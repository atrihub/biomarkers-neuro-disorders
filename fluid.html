<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Biostatistics for Fluid Biomarkers</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.21/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/styles.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: middle, center

# Biostatistics for Fluid Biomarkers

Michael Donohue, PhD

University of Southern California

### Biomarkers for Neurodegenerative Disorders

BarcelonaBeta Brain Research Center

May 2023


  




.pull-left[

&lt;img src="./images/atri.png" width="57%"  style="display: block; margin: auto;" /&gt;

]


.pull-right[

&lt;img src="./images/actc_logo.png" width="47%"  style="display: block; margin: auto;" /&gt;

]

---

# Course Overview

.large[
Topics:

- Hour 1 -- Biostatistics for Fluid Biomarkers
- Hour 2 -- Biostatistics for Imaging Biomarkers
  - Intro to Longitudinal Data
- Hour 3 -- Modeling Longitudinal Data

Emphases:

- Visualization 
- Demonstrations using R, code available from:
  - [https://github.com/atrihub/biomarkers-neuro-disorders](https://github.com/atrihub/biomarkers-neuro-disorders)
]

---

# Session 1 Outline

.large[
- Batch Effects
- Experimental Design (Sample Randomization)
- Statistical Models for Assay Calibration/Quantification
- Classification (Supervised Learning)
  - Logistic Regression
  - Binary Trees
  - Random Forest
- Mixture Modeling (Unsupervised Learning)
  - Univariate
  - Bivariate
- Mixture of Experts (Unsupervised Learning with covariates)
]

---

class: inverse, middle, center

# Batch Effects

---

# Batch Effects: Boxplot



&lt;img src="fluid_fig/batch_data_plot-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Coefficient of Variation

.pull-left[

&lt;table class="table table-striped table-condensed" style="font-size: 18px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; batch &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; N &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Mean &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SD &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SD/Mean = CV (%) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 790 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 379 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 48 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 925 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 299 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 32 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 725 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 389 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 54 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 951 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 332 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 690 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 312 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 45 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 867 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 349 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 40 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 837 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 446 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 53 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 914 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 348 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 883 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 271 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 763 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 266 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

.pull-right[

- Coefficient of Variation (CV) = SD/Mean
- Often used for quality control (reject batch with CV &gt; `\(x\)`)

]

---

# Testing for Batch Effects


```r
anova(lm(Biomarker ~ batch, batch_data))
Analysis of Variance Table

Response: Biomarker
           Df   Sum Sq Mean Sq F value  Pr(&gt;F)    
batch       9  3573109  397012    3.37 0.00051 ***
Residuals 490 57758046  117874                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

* Batch explains a significant amount of the variation in this simulated data
* R note: `batch` variable must be a `factor`, not `numeric` (otherwise, you will get a batch slope)

---

# Batch effects: Confounds

&lt;img src="fluid_fig/batch_confounds-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

Suppose we have groups of interest (say, active vs placebo) that we would like to compare.

Do we see an problem here?

---

class: inverse, middle, center

# Experimental Design for Fluid Biomarkers

---

# Randomized assignment of samples to plates

&lt;img src="fluid_fig/batch_randomized-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

If we have both groups represented in each batch, we can disentangle batch effects
and group effects

One way to ensure this, is to randomize samples to batches

---

# Experimental Design for Fluid Biomarkers

.large[
- Randomize samples to batches/plates
- Longitudinally collected samples (samples collected over time on same individual):
  - If batch effects are expected to be larger than storage effects, consider randomizing *individuals* to batches (i.e. keep all samples from individual on the same plate)
  - However, if storage effects are a concern, timely sample processing might be preferred.
- Randomization can be stratified to ensure important factors (e.g. treatment group, age, APOE `\(\epsilon4\)`) are balanced over batches.
]

---

# Sample Randomization

We use an `R` package [SRS](https://github.com/atrihub/SRS) ("Subject Randomization System"), which we have modified to deal with the constraints of plate capacity, and keeping samples from the same subject together.

(Note this is different than the `SRS` package on CRAN)



&lt;table class="table table-striped table-condensed" style="font-size: 18px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Subject ID &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Num. of samples &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Group &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Age &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Plate &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 11 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 8 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 12 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

# Sample Randomization

.pull-left[

&lt;table class="table table-striped table-condensed" style="font-size: 18px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Plate &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 11 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 12 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 13 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; old &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; young &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Num. samples &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 29 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 29 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 29 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

.pull-right[

- Number of young and old well balanced across the 13 plates
- Number of samples per plate is also reasonable (plate capacity was set at 30 samples)

]

---

class: inverse, middle, center

# Calibration

---

# Calibration

.large[

- Calibration: developing a map from "raw" assay responses to concentrations (ng/ml) using samples of *known* concentrations
- We will explore some approaches to calibration with methods from the `R` package `calibFit` (Haaland et al., 2011; Davidian et al., 1990)
- The package includes some example data:
  - High Performance Liquid Chromatography (HPLC) and 
  - Enzyme Linked Immunosorbent Assay (ELISA)
- These examples are taken straight from the package vignette

]

???

The package is not actively maintained, so you must install the package from the CRAN archive

---

# Calibration

.pull-leftWider[

&lt;img src="fluid_fig/calibFit_fits-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-rightNarrower[

- *Calibration* is *inverse regression* in which these fitted curves would be used to map assay responses from samples of unkown concentration (vertical axis) to concentration values (horizontal axis).
- Both fits exhibit *heteroscedasticity*: the error variance is not constant with respect to Concentration
- Most models assume *homoscedasticity*, or constant error variance.

]

---

# Residuals (difference between response &amp; fitted values)

&lt;img src="fluid_fig/calibFit_residuals-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Typical Regression

Typically, regression models are of the form: 

`\begin{equation}
Y_{i}=f(x_i,\beta)+\epsilon_{i}, 
\end{equation}`

where:

- `\(Y_{i}\)` is the observed response/outcome for `\(i\)`th individual ( `\(i=1,\ldots,n\)` ) 
- `\(x_i\)` are covariates/predictors for `\(i\)`th individual
- `\(\beta\)` are regression coefficients to be estimated
- `\(f(\cdot,\cdot)\)` is the model (assumed "known" or to be estimated)
  - In linear regression `\(f(x_i,\beta)=x_i\beta\)`
- `\(\epsilon_i\)` is the residual error
- We assume `\(\epsilon\sim\mathcal{N}(0,\sigma^2)\)` 
- `\(\sigma\)` is the *constant* standard deviation (*homoscedastic*)

If the standard deviation is not actually constant (*heteroscedastic*), estimates might be unreliable.


---

## Ordinary Least Squares: minimizing the sum of squared residuals

&lt;video width="100%"  controls loop&gt;&lt;source src="fluid_fig/regression-movie.webm" /&gt;&lt;/video&gt;

`\(^*\)` RSS = Residual sum of squares, or `\(\sum_i (\textrm{Observed}_i-\textrm{Fitted}_i)^2\)`

---

# Modeling Heteroscedastic Errors

The `calibFit` package includes models of the form: 

`\begin{equation}
Y_{ij}=f(x_i,\beta)+\sigma g(\mu_i,z_i,\theta) \epsilon_{ij}, 
\end{equation}`

where,

- `\(Y_{ij}\)` are observed assay values/responses for `\(i\)`th individual ( `\(i=1,\ldots,n\)` ), `\(j\)`th replicate
- `\(g(\mu_i,z_i,\theta)\)` is a function that allows the variances to depend on:
  - `\(\mu_i\)` (the mean response `\(f(x_i,\beta)\)`), 
  - covariates `\(z_i\)`, and 
  - a parameter ("known" or unknown) `\(\theta\)`.
- `\(\epsilon_{ij}\sim\mathcal{N}(0,1)\)` 

In particular, `calibFit` implements the Power of the Mean (POM) function

`\begin{equation}
g(\mu_i,\theta) = \mu_i^{2\theta}
\end{equation}`

which results in 

`\begin{equation}
\operatorname{var}(Y_{ij}) = \sigma^2\mu_i^{2\theta}
\end{equation}`

???

allowing the variance to depend on the mean.

---

# "Homogenized" Residuals From Fits with POM



&lt;img src="fluid_fig/calibFit_pom_residuals-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# HPLC Calibration With/Without POM Variance

&lt;img src="fluid_fig/calib_hplc_pom-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

The mean does not change much, but we get more accurate and tighter 95% confidence bands

---

# Elisa Calibration With/Without POM Variance

&lt;img src="fluid_fig/calib_elisa_pom-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Calibrated Estimates for Each Sample

.pull-left[

&lt;img src="fluid_fig/calibrated1-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="fluid_fig/calibrated2-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

???

* MDC is Minimum Detectable Concentration, which we'll define on the next slide

---

# Calibration Statistics

Assuming calibration curve `\(f\)`, mapping concentrations to assay responses, is increasing, we define the following terms.

**Minimum Detectable Concentration (MDC)**: The lowest concentration where the curve is increasing, or:

  `$$x_{\textrm{MDC}} = \min\{x : f(x, \beta) &gt; \textrm{UCL}_0\}$$`
  
  where `\(\textrm{UCL}_0\)` is the upper confidence limit at 0

**Reliable Detection Limit (RDL)**: The lowest concentration that has a high probability of producing a response that is significantly greater than the response at 0, or 
  
`$$x_{\textrm{RDL}} = \min\{x : \textrm{LCL}_x &gt; \textrm{UCL}_0 \}$$`

**Limit of Quantitization (LOQ)**: The lowest concentration at which the coefficient of variation is less than a fixed percent (default is 20% in the `calibFit` package).

---

class: inverse, middle, center

# Supervised Learning

## Classification

---

# Classification

.pull-leftWider[

&lt;img src="fluid_fig/classification-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-rightNarrower[

- Data from [adni.loni.usc.edu](adni.loni.usc.edu)
- CSF Abeta 1-42 and t-tau assayed using the automated Roche Elecsys and cobas e 601 immunoassay analyzer system
- Filter time points associated with first assay, and ignore subsequent time points
- We'll ignore MCI and focus on CN vs Dementia
- Values greater than the upper limit of detection have been assigned the limit

]

---

# Classification

&lt;img src="fluid_fig/classification_no_mci-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Reciever Operatoring Characteristic (ROC) Curves

.pull-left[

&lt;img src="fluid_fig/ROC_abeta-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[

For each potential threshold applied to CSF `\(\textrm{A}\beta 42\)`, 
we calculate:
- Sensitivity: True Positive Rate = TP/(TP+FN)
- Specificity: True Negative Rate = TN/(TN+FP)

This traces out the ROC curve.

A typical summary of a classifier's performance is the
Area Under the Curve (AUC)

AUC=0.83 in this case, with 95% CI ( 0.8, 0.86 )

AUCs close to one indicate good performance.

The threshold shown here maximizes the distance between the curve
and the diagonal line (chance) (Youden, 1950)

]

???

Sensitivity is a measure of how well we are detecting positive cases

Specificity is a measure of how well we are detecting controls or negative cases

Youden's index gives equal weight to false positives and false negatives (not necessarily appropriate)

---

# Comparing ROC Curves

.pull-left[

&lt;img src="fluid_fig/ROC_abeta_tau-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[


| Marker                 | AUC                  | 95% CI                       | P-value `\(^*\)` |
| ---------------------- |:--------------------:| ----------------------------:| ------------:|
| `\(\textrm{A}\beta\)`      | 0.83    | 0.8, 0.86    |              |
| Tau                    | 0.78      | 0.75, 0.82      |  0.07        |
| Tau/ `\(\textrm{A}\beta\)` | 0.9 | 0.87, 0.92 |  &lt;0.001      |
`\(^*\)` Bootstrap test comparing each row to `\(\textrm{A}\beta\)` (Robin et al., 2011)

So the ratio of Tau / `\(\textrm{A}\beta\)` shows the best discrimination of NC from Dementia cases.



]

---

# Youden's Cutoff for Tau / `\(\textrm{A}\beta\)` Ratio

&lt;img src="fluid_fig/abeta_tau_scatter_youden-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

Line is Tau = 0.394 `\(\times\)` Abeta, depicting Youden's cutoff (maximizes sensitivity + specificity)

???

Youden's cutoff maximizing sensitivity + specificity is appropriate if sensitivity and specificity are equally important

---

# Logistic Regression

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Coefficient &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; z value &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Pr(&amp;gt;|z|) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.89 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -6.7 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(ABETA) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.59 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -10.6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(TAU) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.26 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.14 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.0 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

`$$\log\big(\frac{p}{1-p}\big) = \hat\gamma_0 + A\beta_z \hat\gamma_{A\beta} + \textrm{tau}_z \hat\gamma_{\textrm{tau}}$$`
where `\(\hat\gamma\)` are regression coefficients.

---

# Logistic Regression Predicted Probabilities

&lt;img src="fluid_fig/logistic_pred_prob-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

line again depicts Youden's cutoff

---

# Ratio Contours

&lt;img src="fluid_fig/ratio_gradient-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

by using ratio's we're simplifying the bivariate scatter by assuming all dots along
these lines intersecting (0,0) are equivalent

dashed line has slope 1
---


# Logistic Regression Predicted Probability Contours

&lt;img src="fluid_fig/ratio_gradient_logistic-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

in contrast, logistic regression assumes the predicted probability gradient follows these
parallel lines

lines now are where predicted probabilities from logistic regression are constant

---

# Comparing ROC Curves

.pull-left[

&lt;img src="fluid_fig/ROC_logistic-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[


| Marker                 | AUC                      | 95% CI                           | P-value `\(^*\)` |
| ---------------------- |:------------------------:| --------------------------------:| ------------:|
| `\(\textrm{A}\beta\)`      | 0.83        | 0.8, 0.86        |              |
| Tau                    | 0.78          | 0.75, 0.82          |  0.07        |
| Tau/ `\(\textrm{A}\beta\)` | 0.9     | 0.87, 0.92     |  &lt;0.001      |
| Logisitic model        | 0.9 | 0.87, 0.92 |  &lt;0.001      |
`\(^*\)` Bootstrap test comparing each row to `\(\textrm{A}\beta\)` (Robin et al., 2011)

Logistic model ROC is very similar to Tau/ `\(\textrm{A}\beta\)` ratio ROC.



]

---

# Logistic Regression with Age and APOE

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Coefficient &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; z value &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Pr(&amp;gt;|z|) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.17 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -6.5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(ABETA) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.43 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.16 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -9.0 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(TAU) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.19 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.14 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8.5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &amp;lt;0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; scale(I(AGE + Years.bl)) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.14 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.230 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; as.factor(APOE4)1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.37 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.25 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.144 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; as.factor(APOE4)2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.26 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.45 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 0.005 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



This model does not provide much better ROC, either.

---

# Regression Trees

&lt;img src="fluid_fig/tree1-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

Hothorn et al. (2006)

???

Regression trees use recursive partitioning to classify data into more and more homogeneous subgroups

---

# Tree-based Methods

&lt;img src="fluid_fig/tree2-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

With this shallow tree, we end up with these four partitions of the Abeta-by-Tau scatter

---

# Comparing ROC Curves

.pull-left[

&lt;img src="fluid_fig/ROC_rf-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

]

.pull-right[


| Marker                 | AUC                      | 95% CI                           | P-value `\(^*\)` |
| ---------------------- |:------------------------:| --------------------------------:| ------------:|
| `\(\textrm{A}\beta\)`      | 0.83        | 0.8, 0.86        |              |
| Tau                    | 0.78          | 0.75, 0.82          |  0.07        |
| Tau/ `\(\textrm{A}\beta\)` | 0.9     | 0.87, 0.92     |  &lt;0.001      |
| Logisitic model        | 0.9 | 0.87, 0.92 |  &lt;0.001      |
| Binary Tree            | 0.88     | 0.86, 0.91     |  &lt;0.001      |
| Random Forest          | 0.95       | 0.93, 0.96       |  &lt;0.001      |
`\(^*\)` Bootstrap test comparing each row to `\(\textrm{A}\beta\)` (Robin et al., 2011)

Random Forests (Breiman, 2001; Hothorn et al., 2006) re-fit binary trees on random subsamples of the data, then aggregate resulting trees into a "forest". This results in smoother predictions and a smoother ROC curve.

* All three models should be (cross) validated, since they learn from known Dx.



]

---

class: inverse, middle, center

# Unsupervised Learning

## Mixture Modeling

---

# Unsupervised Learning

.large[
- The classification techniques we just reviewed can be thought of as *Supervised Learning* in which we attempt to learn known "labels" (CN, Dementia).
- *Mixture Modeling* is type of *Unsupervised Learning* technique in which we try to identify clusters of populations which appear to be arising from different distributions
- Don't confuse *Mixture Models* with *Mixed-Effects Models* (which we'll discuss later)
  - Think: "Mixture of Distributions"
]

---

# Distribution of ABETA

&lt;img src="fluid_fig/density_Abeta-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

- Distribution is bimodal
- Can we identify the two sub-distributions?
- We'll explore with `mixtools` package (Benaglia et al., 2009)

---

# Distribution of ABETA



&lt;img src="fluid_fig/mixture_distribution_Abeta-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

???

mixture models provide latent class membership probabilities, such as these 

---

# Posterior Membership Probabilities

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Abeta &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Prob. Abnormal &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Prob. Normal &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1033 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.58 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.42 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1036 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.57 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.43 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1044 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.53 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.47 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1048 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.52 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.48 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1061 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.46 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.54 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1071 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.42 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.58 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1071 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.42 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.58 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1072 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.41 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.59 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

## Bivariate Density



&lt;iframe src="bvdensity_csf_tau.html" width="100%" height="500" id="igraph" scrolling="no" seamless="seamless" frameBorder="0"&gt; &lt;/iframe&gt;

---

# Bivariate Density Contour Plot

&lt;img src="fluid_fig/bv_kernel_density-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

---

# Bivariate Mixture Model Posterior Probabilities

.pull-left[
&lt;img src="fluid_fig/mvmix_post_prob-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="fluid_fig/mvmix_density-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;
]

???

line on the left is still Youden's cutoff for the ratio

Contours are confidence ellipses at 99%, 95%, and 90% just to help see the shape of the estimated distributions

---

# Mixture of Experts (unsupervised learning with covariates)

&lt;img src="./images/moe.png" width="60%"  style="display: block; margin: auto;" /&gt;

Murphy et al. (2020); Murphy and Murphy (2022)

---

# Mixture of Experts (unsupervised learning with covariates)

&lt;img src="fluid_fig/unnamed-chunk-15-1.svg" width="100%"  style="display: block; margin: auto;" /&gt;

MAP = maximum a posteriori classification

---

# Summary

.large[
- Batch Effects
- Experimental Design (Sample Randomization)
- Statistical Models for Assay Calibration/Quantification
- Classification (Supervised Learning)
  - Logistic Regression
  - Binary Trees
  - Random Forest
- Mixture Modeling (Unsupervised Learning)
  - Univariate
  - Bivariate
  - With covariates (Mixture of Experts)
]

---

# References (1/2)

Benaglia, T., D. Chauveau, D. R. Hunter, and D. Young (2009).
"mixtools: An R Package for Analyzing Finite Mixture Models". In:
_Journal of Statistical Software_ 32.6, pp. 1-29. URL:
[http://www.jstatsoft.org/v32/i06/](http://www.jstatsoft.org/v32/i06/).

Breiman, L. (2001). "Random forests". In: _Machine learning_ 45.1, pp.
5-32.

Davidian, M. and P. D. Haaland (1990). "Regression and calibration with
nonconstant error variance". In: _Chemometrics and Intelligent
Laboratory Systems_ 9.3, pp. 231-248.

Haaland, P., D. Samarov, and E. McVey (2011). _calibFit: Statistical
models and tools for assay calibration_. R package version 2.1.0. URL:
[https://CRAN.R-project.org/package=calibFit](https://CRAN.R-project.org/package=calibFit).

Hothorn, T., P. Buehlmann, S. Dudoit, A. Molinaro, and M. Van Der Laan
(2006). "Survival Ensembles". In: _Biostatistics_ 7.3, pp. 355-373.

Hothorn, T., K. Hornik, and A. Zeileis (2006). "Unbiased Recursive
Partitioning: A Conditional Inference Framework". In: _Journal of
Computational and Graphical Statistics_ 15.3, pp. 651-674.

Murphy, K. and T. B. Murphy (2022). _\texttt\textupMoEClust: Gaussian
Parsimonious Clustering Models with Covariates and a Noise Component_.
\textsfR package version 1.5.0. URL:
[https://cran.r-project.org/package=MoEClust](https://cran.r-project.org/package=MoEClust).

---

# References (2/2)

Murphy, K. and T. B. Murphy (2020). "Gaussian Parsimonious Clustering
Models with Covariates and a Noise Component". In: _Advances in Data
Analysis and Classification_ 14.2, pp. 293-325. DOI:
[10.1007/s11634-019-00373-8](https://doi.org/10.1007%2Fs11634-019-00373-8).
URL:
[https://doi.org/10.1007/s11634-019-00373-8](https://doi.org/10.1007/s11634-019-00373-8).

Robin, X., N. Turck, A. Hainard, N. Tiberti, F. Lisacek, J. Sanchez,
and M. MÃ¼ller (2011). "pROC: an open-source package for R and S+ to
analyze and compare ROC curves". In: _BMC Bioinformatics_ 12, p. 77.

Youden, W. J. (1950). "Index for rating diagnostic tests". In: _Cancer_
3.1, pp. 32-35.

---

# Session Info


```
R version 4.2.2 (2022-10-31)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Big Sur ... 10.16

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib

attached base packages:
[1] stats4    grid      stats     graphics  grDevices datasets  utils    
[8] methods   base     

other attached packages:
 [1] RefManageR_1.4.0  MoEClust_1.5.1    party_1.3-13      strucchange_1.5-3
 [5] sandwich_3.0-2    zoo_1.8-12        modeltools_0.2-23 mvtnorm_1.1-3    
 [9] pROC_1.18.0       mixtools_2.0.0    SRS_0.03          calibFit_2.1.0   
[13] nlme_3.1-160      plotly_4.10.1     gridExtra_2.3     kableExtra_1.3.4 
[17] lubridate_1.9.2   forcats_1.0.0     stringr_1.5.0     dplyr_1.1.2      
[21] purrr_1.0.1       readr_2.1.4       tidyr_1.3.0       tibble_3.2.1     
[25] ggplot2_3.4.2     tidyverse_2.0.0   knitr_1.42       

loaded via a namespace (and not attached):
 [1] segmented_1.6-4     matrixStats_0.63.0  webshot_0.5.4      
 [4] httr_1.4.6          backports_1.4.1     tools_4.2.2        
 [7] bslib_0.4.2         utf8_1.2.3          R6_2.5.1           
[10] lazyeval_0.2.2      colorspace_2.1-0    nnet_7.3-18        
[13] withr_2.5.0         tidyselect_1.2.0    compiler_4.2.2     
[16] cli_3.6.1           rvest_1.0.3         xml2_1.3.4         
[19] isoband_0.2.7       labeling_0.4.2      sass_0.4.6         
[22] scales_1.2.1        lmtest_0.9-40       systemfonts_1.0.4  
[25] mvnfast_0.2.8       digest_0.6.31       rmarkdown_2.21     
[28] svglite_2.1.1       pkgconfig_2.0.3     htmltools_0.5.5    
[31] bibtex_0.5.1        highr_0.10          fastmap_1.1.1      
[34] htmlwidgets_1.6.2   rlang_1.1.1         rstudioapi_0.14    
[37] xaringan_0.28       farver_2.1.1        jquerylib_0.1.4    
[40] generics_0.1.3      jsonlite_1.8.4      crosstalk_1.2.0    
[43] mclust_6.0.0        magrittr_2.0.3      Matrix_1.5-1       
[46] Rcpp_1.0.10         munsell_0.5.0       fansi_1.0.4        
[49] lifecycle_1.0.3     stringi_1.7.12      multcomp_1.4-23    
[52] yaml_2.3.7          MASS_7.3-58.1       plyr_1.8.8         
[55] parallel_4.2.2      lattice_0.20-45     splines_4.2.2      
[58] hms_1.1.3           pillar_1.9.0        codetools_0.2-18   
[61] glue_1.6.2          evaluate_0.21       data.table_1.14.8  
[64] renv_0.16.0         vcd_1.4-11          vctrs_0.6.2        
[67] tzdb_0.3.0          gtable_0.3.3        kernlab_0.9-32     
[70] cachem_1.0.8        xfun_0.39           coin_1.4-2         
[73] libcoin_1.0-9       survival_3.4-0      viridisLite_0.4.2  
[76] ADNIMERGE_0.0.1     timechange_0.2.0    ellipsis_0.3.2     
[79] TH.data_1.1-2       xaringanExtra_0.7.0
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "solarized-light",
"highlightLanguage": ["r", "css", "yaml"],
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
